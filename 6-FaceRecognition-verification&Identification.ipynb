{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<start>only for colab users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/alireza.jpg -P images\n",
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/ali.jpg -P images\n",
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/mohsen.jpg -P images\n",
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/muhammad.jpg -P images\n",
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/1.jpg -P images\n",
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/srttu-class.png -P images\n",
    "!wget https://github.com/Alireza-Akhavan/deep-face-recognition/raw/master/images/m_wrapped.png -P images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/Alireza-Akhavan/deep-face-recognition/master/ArcFace.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<end>only for colab users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ArcFace\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ArcFace.loadModel()\n",
    "face_detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(img):\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #mtcnn expects RGB but OpenCV read BGR\n",
    "    detections = face_detector.detect_faces(img_rgb)\n",
    "    detection = detections[0]\n",
    "    x, y, w, h = detection[\"box\"]\n",
    "    detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n",
    "    return detected_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_face(img, target_size=(112,112)):\n",
    "    img = cv2.imread(img)\n",
    "    img = detect_face(img)\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img_pixels = image.img_to_array(img)\n",
    "    img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "    img_pixels /= 255 #normalize input in [0, 1]\n",
    "    return img_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(path):\n",
    "    img = preprocess_face(path)\n",
    "    return model.predict(img)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "\n",
    "database[\"alireza\"] = img_to_encoding(\"./images/alireza.jpg\")\n",
    "database[\"ali\"] = img_to_encoding(\"./images/ali.jpg\")\n",
    "database[\"mohsen\"] = img_to_encoding(\"./images/mohsen.jpg\")\n",
    "database[\"muhammad\"] = img_to_encoding(\"./images/muhammad.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_threshhold = 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database):\n",
    "    # Step 1: Compute the encoding for the image. Use img_to_encoding()\n",
    "    encoding = img_to_encoding(image_path) \n",
    "    \n",
    "    # Step 2: Compute distance with identity's image\n",
    "    dist = EuclideanDistance(encoding, database[identity])\n",
    "    \n",
    "    # Step 3: Open the door if dist < verification_threshhold, else don't open\n",
    "    if dist < verification_threshhold:\n",
    "        print(\"It's \" + str(identity) + \", welcome!\")\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "             \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/1.jpg' style=\"width: 100px;\"><img src='images/alireza.jpg' style=\"width: 100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's alireza, welcome!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2458622"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/1.jpg\", \"alireza\", database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/ali.jpg' style=\"width: 100px;\"><img src='images/alireza.jpg' style=\"width: 100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not alireza, please go away\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.855377"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(\"images/ali.jpg\", \"alireza\", database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def who_is_it(image_path, database):\n",
    "   \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding()\n",
    "    encoding = img_to_encoding(image_path)\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    \n",
    "    # Initialize \"min_dist\" to a large value, say 100 \n",
    "    min_dist = 1000\n",
    "    # Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        # Compute L2 distance between the target \"encoding\" and the current \"emb\" from the database. (≈ 1 line)\n",
    "        dist = EuclideanDistance(encoding, db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
    "        if min_dist > dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "\n",
    "  \n",
    "    if min_dist > verification_threshhold:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/srttu-class.png' style=\"width: 300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's alireza, the distance is 3.835887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.835887, 'alireza')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/srttu-class.png\", database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/m.jpg' style=\"width: 160px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11.598342, 'alireza')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/m.jpg\", database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='images/m_wrapped.jpg' style=\"width: 160px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it's mohsen, the distance is 4.3644657\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.3644657, 'mohsen')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(\"images/m_wrapped.jpg\", database)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
